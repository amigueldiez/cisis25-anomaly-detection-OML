{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different approaches to anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python notebook proposes three different approaches for anomaly detection in network flows. In addition, their advantages and disadvantages are detailed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from river import anomaly\n",
    "from river import preprocessing\n",
    "from river import optim\n",
    "from river import sketch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training flows for the online learning algorithm\n",
    "FLOWS_TRAIN_SCALER = 1000\n",
    "FLOWS_TRAIN_OML = 100000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was created based on one of the datasets provided by Proactivanet. Subsequently, the following anomalies were introduced, with 2,500 flows of each type:\n",
    "\n",
    "- Benign IP connecting to an anomalous IP during working hours\n",
    "- Benign IP connecting to a benign IP at an anomalous time\n",
    "- Benign IP connecting to an anomalous domain during working hours\n",
    "- Benign IP connecting to an anomalous domain at an anomalous time\n",
    "- Anomalous IP connecting to an anomalous IP during working hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Match Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH_DATASET2 = './dataset/'\n",
    "DATASET_NAME_DATASET2 = 'dataset_anonymized.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "dataset = pd.read_csv(DATASET_PATH_DATASET2 + DATASET_NAME_DATASET2, sep=',')\n",
    "\n",
    "# Use the following features\n",
    "dataset = dataset[['FIRST_SWITCHED', 'IPV_SRC_ADDR', 'L_SRC_PORT', 'IPV_DST_ADDR', 'DIRECTION', 'L_DST_PORT', 'IN_BYTES', 'OUT_BYTES', 'Label']]\n",
    "\n",
    "# The FIRST_SWITCHED feature is converted into the hour of the day\n",
    "dataset['FIRST_SWITCHED'] = pd.to_datetime(dataset['FIRST_SWITCHED']).dt.hour\n",
    "\n",
    "# A PORT feature is created that is L_SRC_PORT if DIRECTION is 0 and L_DST_PORT if DIRECTION is 1\n",
    "dataset['PORT'] = np.where(dataset['DIRECTION'] == 0, dataset['L_SRC_PORT'], dataset['L_DST_PORT'])\n",
    "\n",
    "# Remove the columns L_SRC_PORT, L_DST_PORT, and DIRECTION\n",
    "dataset = dataset.drop(columns=['L_SRC_PORT', 'L_DST_PORT', 'DIRECTION'])\n",
    "\n",
    "# Preprocess IN_BYTES and OUT_BYTES by rounding to the nearest multiple of 100\n",
    "dataset['IN_BYTES'] = dataset['IN_BYTES'].apply(lambda x: round(x, -2))\n",
    "dataset['OUT_BYTES'] = dataset['OUT_BYTES'].apply(lambda x: round(x, -2))\n",
    "\n",
    "# Remove label\n",
    "dataset_sin_etiqueta = dataset.drop(columns=['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  100000\n"
     ]
    }
   ],
   "source": [
    "# Create the training set\n",
    "X_train = dataset_sin_etiqueta[dataset['Label'] == 0].iloc[:100000]\n",
    "print(\"Number of training samples: \", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "\n",
    "for row in X_train.iterrows():\n",
    "    key = tuple(row[1].values)\n",
    "    model[key] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El procedimiento anterior es igual al descrito anteriormente. Sin embargo, en este caso se ha entrenado con 200000 flujos benignos. En este caso, la fase de evaluación se ha realizado con 12500 flujos benignos y 12500 anómalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies in the test dataset:  12500\n",
      "Number of normal samples in the test dataset:  12500\n"
     ]
    }
   ],
   "source": [
    "# Create the test set\n",
    "X_test = dataset_sin_etiqueta[dataset['Label'] == 1].iloc[:12500]\n",
    "X_test = pd.concat([X_test, dataset_sin_etiqueta[dataset['Label'] == 0].iloc[100000:112500]], ignore_index=True)\n",
    "\n",
    "# Create the test set labels (1 for anomalies, 0 for normal flows)\n",
    "y_test = np.ones(12500)\n",
    "y_test = np.concatenate([y_test, np.zeros(12500)])\n",
    "\n",
    "print(\"Number of anomalies in the test dataset: \", y_test[y_test == 1].shape[0])\n",
    "print(\"Number of normal samples in the test dataset: \", y_test[y_test == 0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.741\n",
      "Recall:  1.0\n",
      "False Positive Rate:  0.518\n",
      "TP:  12500 TN:  6025 FP:  6475 FN:  0\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for i, row in X_test.iterrows():\n",
    "\n",
    "    key = tuple(row.values)\n",
    "    is_anomaly = not key in model\n",
    "    label = y_test[i]\n",
    "    if is_anomaly and label == 1:\n",
    "        tp += 1\n",
    "    elif not is_anomaly and label == 0:\n",
    "        tn += 1\n",
    "    elif is_anomaly and label == 0:\n",
    "        fp += 1\n",
    "    elif not is_anomaly and label == 1:\n",
    "        fn += 1\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "false_positive = fp / (fp + tn)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"False Positive Rate: \", false_positive)\n",
    "print(\"TP: \", tp, \"TN: \", tn, \"FP: \", fp, \"FN: \", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All anomalies are correctly detected (recall = 1), but the number of false positives is very high. This is due to the model's inability to generalize, as it relies on exact match searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning - DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "dataset = dataset.sample(frac=1, random_state=111).reset_index(drop=True)\n",
    "\n",
    "# Create LabelEncoder objects\n",
    "le_src = LabelEncoder()\n",
    "le_dst = LabelEncoder()\n",
    "\n",
    "# Fit and transform the IPV_SRC_ADDR and IPV_DST_ADDR features\n",
    "dataset['IPV_SRC_ADDR'] = le_src.fit_transform(dataset['IPV_SRC_ADDR'])\n",
    "dataset['IPV_DST_ADDR'] = le_dst.fit_transform(dataset['IPV_DST_ADDR'])\n",
    "\n",
    "# Remove label column\n",
    "dataset_sin_etiqueta = dataset.drop(columns=['Label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model was trained with 100,000 benign flows and 6,250 anomalous flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train = dataset_sin_etiqueta[dataset['Label'] == 0].iloc[:93750]\n",
    "# y_train contains 0s\n",
    "y_train = np.zeros(93750)\n",
    "\n",
    "# Add 6,250 anomalous flows to the training set\n",
    "X_train = pd.concat([X_train, dataset_sin_etiqueta[dataset['Label'] == 1].iloc[:6250]])\n",
    "\n",
    "# Add 1s to y_train for the anomalous samples\n",
    "y_train = np.concatenate([y_train, np.ones(6250)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training dataset:  100000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples in the training dataset: \", y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=987)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=987)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=987)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Grid Search for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters: \", best_params)\n",
    "# Create the Decision Tree Classifier with the best parameters\n",
    "clf = DecisionTreeClassifier(**best_params, random_state=987)\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation, 6,250 benign flows and 6,250 anomalous flows will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the anomalous flows from the dataset\n",
    "X_test = dataset_sin_etiqueta[dataset['Label'] == 1].iloc[6250:]\n",
    "y_test = np.ones(X_test.shape[0])\n",
    "\n",
    "# Add 6,250 benign flows to the test set\n",
    "X_test = pd.concat([X_test, dataset_sin_etiqueta[dataset['Label'] == 0].iloc[93750:100000]])\n",
    "y_test = np.concatenate([y_test, np.zeros(6250)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the test dataset:  12500\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples in the test dataset: \", y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.99976\n",
      "Recall:  0.99952\n",
      "False Positive Rate:  0.0\n",
      "TP:  6247 TN:  6250 FP:  0 FN:  3\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "tp = np.sum((y_pred == 1) & (y_test == 1))\n",
    "tn = np.sum((y_pred == 0) & (y_test == 0))\n",
    "fp = np.sum((y_pred == 1) & (y_test == 0))\n",
    "fn = np.sum((y_pred == 0) & (y_test == 1))\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "# If there are no true positives, recall is 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "false_positive = fp / (fp + tn)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"False Positive Rate: \", false_positive)\n",
    "print(\"TP: \", tp, \"TN: \", tn, \"FP: \", fp, \"FN: \", fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the results are better than those obtained with the exact match search. Most anomalies are successfully detected, and the number of false positives is lower. However, it is important to note that a labeled dataset is required to train the model. Furthermore, it is very difficult for the model to generalize across different networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Online Learning Using One-Class SVM (oSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "dataset = pd.read_csv(DATASET_PATH_DATASET2 + DATASET_NAME_DATASET2, sep=',', index_col=False)\n",
    "\n",
    "# Features\n",
    "FEATURES = ['IPV_SRC_ADDR', 'IPV_DST_ADDR', 'L_DST_PORT', 'L_SRC_PORT', 'DIRECTION', 'FIRST_SWITCHED', 'LAST_SWITCHED', 'PROTOCOL', 'END_TYPE', 'IN_BYTES', 'OUT_BYTES', 'Label']\n",
    "\n",
    "# Preprocess flows\n",
    "dataset = dataset[FEATURES]\n",
    "dataset = dataset.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ | MODE SIGNIFICANT PORT ACTIVATED\n",
      "✅ | Significant port added\n"
     ]
    }
   ],
   "source": [
    "# Significative port\n",
    "print(\"ℹ️ | MODE SIGNIFICANT PORT ACTIVATED\")\n",
    "for i in range(len(dataset)):\n",
    "    if dataset[i][FEATURES.index('DIRECTION')] == 1:\n",
    "        dataset[i][FEATURES.index('DIRECTION')] = dataset[i][FEATURES.index('L_DST_PORT')]\n",
    "    else:\n",
    "        dataset[i][FEATURES.index('DIRECTION')] = dataset[i][FEATURES.index('L_SRC_PORT')]\n",
    "print('✅ | Significant port added')\n",
    "    \n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i][FEATURES.index('FIRST_SWITCHED')] = int(dataset[i][FEATURES.index('FIRST_SWITCHED')].split(' ')[1].split(':')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform numpy array to pandas dataframe\n",
    "dataset = pd.DataFrame(dataset, columns=FEATURES)\n",
    "\n",
    "# Significant port\n",
    "dataset = dataset.drop(columns=['L_SRC_PORT', 'L_DST_PORT'])\n",
    "# Change DIRECTION column name to PORT\n",
    "dataset = dataset.rename(columns={'DIRECTION': 'PORT'})\n",
    "\n",
    "\n",
    "\n",
    "# Create the two datasets for trainning\n",
    "datasets_training = dataset.loc[dataset['Label'] == 0].iloc[:FLOWS_TRAIN_SCALER + FLOWS_TRAIN_OML]\n",
    "dataset_train_scaler = datasets_training.loc[dataset['Label'] == 0].iloc[:FLOWS_TRAIN_SCALER]\n",
    "dataset_train_oml = datasets_training.loc[dataset['Label'] == 0].iloc[FLOWS_TRAIN_SCALER:FLOWS_TRAIN_SCALER + FLOWS_TRAIN_OML + 1]\n",
    "\n",
    "\n",
    "# Drop train_scaler and train_oml from the dataset\n",
    "dataset = dataset.drop(dataset_train_scaler.index)\n",
    "dataset = dataset.drop(dataset_train_oml.index)\n",
    "\n",
    "\n",
    "# Number of anomalies and normal samples\n",
    "anomalies_samples= dataset.loc[dataset['Label'] == 1].shape[0]\n",
    "benign_samples = dataset.loc[dataset['Label'] == 0].shape[0]\n",
    "\n",
    "# Drop benign samples to equilibrate the dataset\n",
    "if benign_samples > anomalies_samples:\n",
    "    dataset = dataset.drop(dataset.loc[dataset['Label'] == 0].index[:benign_samples - anomalies_samples])\n",
    "else:\n",
    "    dataset = dataset.drop(dataset.loc[dataset['Label'] == 1].index[:anomalies_samples- benign_samples])\n",
    "\n",
    "# Create the test dataset\n",
    "dataset_test_labeled = dataset\n",
    "\n",
    "# Shuffle the datasets\n",
    "dataset_train_scaler = dataset_train_scaler.sample(frac=1,random_state=111).reset_index(drop=True)\n",
    "dataset_train_oml = dataset_train_oml.sample(frac=1,random_state=111).reset_index(drop=True)\n",
    "dataset_test_labeled = dataset_test_labeled.sample(frac=1,random_state=111).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.OrdinalEncoder()\n",
    "\n",
    "for i in range(len(dataset_train_scaler)):\n",
    "    # Obtain first two elements (IP addresses) pandas datraframe\n",
    "    first_two_elements = {j: str(dataset_train_scaler.iloc[i, j]) for j in range(2)}\n",
    "    # Encode the IP addresses\n",
    "    encoder.learn_one(first_two_elements)\n",
    "    first_two_elements = encoder.transform_one(first_two_elements)\n",
    "    dataset_train_scaler.iloc[i, 0] = first_two_elements[0]\n",
    "    dataset_train_scaler.iloc[i, 1] = first_two_elements[1]\n",
    "\n",
    "for i in range(len(dataset_train_oml)):\n",
    "    # Obtain first two elements (IP addresses)\n",
    "    first_two_elements = {j: str(dataset_train_oml.iloc[i, j]) for j in range(2)}\n",
    "    # Encode the IP addresses\n",
    "    encoder.learn_one(first_two_elements)\n",
    "    first_two_elements = encoder.transform_one(first_two_elements)\n",
    "    dataset_train_oml.iloc[i, 0] = first_two_elements[0]\n",
    "    dataset_train_oml.iloc[i, 1] = first_two_elements[1]\n",
    "\n",
    "for i in range(len(dataset_test_labeled)):\n",
    "    # Obtain first two elements (IP addresses)\n",
    "    first_two_elements = {j: str(dataset_test_labeled.iloc[i, j]) for j in range(2)}\n",
    "    # Encode the IP addresses\n",
    "    encoder.learn_one(first_two_elements)\n",
    "    first_two_elements = encoder.transform_one(first_two_elements)\n",
    "    dataset_test_labeled.iloc[i, 0] = first_two_elements[0]\n",
    "    dataset_test_labeled.iloc[i, 1] = first_two_elements[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================================\n",
      "Number of anomalies in the train scaler dataset:\t 0\n",
      "Number of normal samples in the train scaler dataset:\t 1000\n",
      "Number of normal samples in the trainOML dataset:\t 100000\n",
      "Number of anomaly samples in the trainOML dataset:\t 0\n",
      "Number of anomalies in the test dataset:\t 12500\n",
      "Number of normal samples in the test dataset:\t 12500\n",
      "=====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('=====================================================================================================')\n",
    "print('Number of anomalies in the train scaler dataset:\\t', dataset_train_scaler.loc[dataset_train_scaler['Label'] == 1].shape[0])\n",
    "print('Number of normal samples in the train scaler dataset:\\t', dataset_train_scaler.loc[dataset_train_scaler['Label'] == 0].shape[0])\n",
    "\n",
    "print('Number of normal samples in the trainOML dataset:\\t', dataset_train_oml.loc[dataset_train_oml['Label'] == 0].shape[0])\n",
    "print('Number of anomaly samples in the trainOML dataset:\\t', dataset_train_oml.loc[dataset_train_oml['Label'] == 1].shape[0])\n",
    "\n",
    "print('Number of anomalies in the test dataset:\\t', dataset_test_labeled.loc[dataset_test_labeled['Label'] == 1].shape[0])\n",
    "print('Number of normal samples in the test dataset:\\t', dataset_test_labeled.loc[dataset_test_labeled['Label'] == 0].shape[0])\n",
    "print('=====================================================================================================')\n",
    "\n",
    "# Obtain the datasets without the label\n",
    "dataset_train_no_labels = np.delete(dataset_train_oml, -1, axis=1)\n",
    "dataset_test_no_labels = np.delete(dataset_test_labeled, -1, axis=1)\n",
    "dataset_train_scaler = dataset_train_scaler.drop(columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ | Dataset Scaled\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MaxAbsScaler()\n",
    "\n",
    "scaler_dataset_train = []\n",
    "scaler_dataset_test = []\n",
    "\n",
    "# Convert the dataset to pandas DataFrame format\n",
    "dataset_train_scaler = pd.DataFrame(dataset_train_scaler)\n",
    "dataset_train_no_labels = pd.DataFrame(dataset_train_no_labels)\n",
    "dataset_test_no_labels = pd.DataFrame(dataset_test_no_labels)\n",
    "\n",
    "# Train the scaler model using the training dataset\n",
    "for _, row in dataset_train_scaler.iterrows():\n",
    "    # Convert row to dict using keys 0, 1, 2, 3, ...\n",
    "    row = {i: value for i, value in enumerate(row)}\n",
    "    scaler.learn_one(row)\n",
    "\n",
    "# Scale the training dataset using the trained scaler\n",
    "for _, row in dataset_train_no_labels.iterrows():\n",
    "    row = row.to_dict()\n",
    "    row = scaler.transform_one(row)\n",
    "    scaler_dataset_train.append(list(row.values()))\n",
    "\n",
    "# Scale the test dataset using the previously trained scaler\n",
    "for _, row in dataset_test_no_labels.iterrows():\n",
    "    row = row.to_dict()\n",
    "    row = scaler.transform_one(row)\n",
    "    scaler_dataset_test.append(list(row.values()))\n",
    "\n",
    "print(\"✅ | Dataset Scaled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = anomaly.QuantileFilter(\n",
    "        anomaly.OneClassSVM(nu=0.05,intercept_lr=optim.schedulers.InverseScaling(learning_rate=0.25)),\n",
    "        q = 0.99\n",
    "    )\n",
    "\n",
    "probability_preprocessing = preprocessing.MinMaxScaler()\n",
    "probability = sketch.Histogram()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ | Training OML\n",
      "✅ | Training phase completed\n"
     ]
    }
   ],
   "source": [
    "# Traning phase of OML\n",
    "print(\"⏳ | Training OML\")\n",
    "for row in scaler_dataset_train:\n",
    "    # Change dict to numpy array\n",
    "    row_dict = {f'feature_{i}': value for i, value in enumerate(row)}\n",
    "\n",
    "    model.learn_one(row_dict)\n",
    "\n",
    "    score = model.score_one(row_dict)\n",
    "    probability_preprocessing.learn_one({0: score})\n",
    "    probability.update(probability_preprocessing.transform_one({0: score})[0])\n",
    "\n",
    "print(\"✅ | Training phase completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ | Testing phase completed\n",
      "🟢 | Accuracy:  0.98712\n",
      "🟢 | Recall:  0.98608\n",
      "🟢 | False Positive Rate:  0.01184\n",
      "TP:  12326 TN:  12352 FP:  148 FN:  174\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "fn = 0\n",
    "tp = 0\n",
    "tn = 0\n",
    "accuracies = []\n",
    "recalls = []\n",
    "false_positives = []\n",
    "anomalies = []\n",
    "\n",
    "\n",
    "\n",
    "for i, row in enumerate(scaler_dataset_test):\n",
    "    # To dict\n",
    "    if isinstance(row, list):\n",
    "        row = {f'feature_{j}': value for j, value in enumerate(row)}\n",
    "\n",
    "    score = model.score_one(row)\n",
    "    anomalo = model.classify(score)\n",
    "    anomalies.append(anomalo)\n",
    "\n",
    "    # Update probability\n",
    "    probability_preprocessing.learn_one({0: score})\n",
    "    probability.update(probability_preprocessing.transform_one({0: score})[0])\n",
    "    rank = probability.cdf(probability_preprocessing.transform_one({0: score})[0])\n",
    "\n",
    "\n",
    "    if not anomalo:\n",
    "        model.learn_one(row)\n",
    "\n",
    "    label = dataset_test_labeled.iloc[i, -1]\n",
    "\n",
    "    if anomalo and label == 1:\n",
    "        tp += 1\n",
    "    elif not anomalo and label == 0:\n",
    "        tn += 1\n",
    "    elif anomalo and label == 0:\n",
    "        fp += 1\n",
    "    elif not anomalo and label == 1:\n",
    "        fn += 1\n",
    "        \n",
    "    accuracies.append((tp + tn) / (tp + tn + fp + fn))\n",
    "    recalls.append(tp / (tp + fn) if (tp + fn) > 0 else 0)\n",
    "    false_positives.append(fp / (fp + tn) if (fp + tn) > 0 else 0)\n",
    "\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "false_positive = fp / (fp + tn)\n",
    "print(\"✅ | Testing phase completed\")\n",
    "print(\"🟢 | Accuracy: \", accuracy)\n",
    "print(\"🟢 | Recall: \", recall)\n",
    "print(\"🟢 | False Positive Rate: \", false_positive)\n",
    "print(\"TP: \", tp, \"TN: \", tn, \"FP: \", fp, \"FN: \", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results were achieved by this model, which is capable of detecting anomalies without relying on a labeled dataset—in other words, by analyzing the underlying patterns in the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
